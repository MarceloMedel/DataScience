{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imutils import build_montages\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listar las imagenes a las que queremos extraer un vector\n",
    "imagePaths = list(paths.list_images('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    #print(\"[INFO] processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
    "    #print(imagePath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#print('[INFO] end of processing images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando imagen 1/129\n",
      "Procesando imagen 2/129\n",
      "Procesando imagen 3/129\n",
      "Procesando imagen 4/129\n",
      "Procesando imagen 5/129\n",
      "Procesando imagen 6/129\n",
      "Procesando imagen 7/129\n",
      "Procesando imagen 8/129\n",
      "Procesando imagen 9/129\n",
      "Procesando imagen 10/129\n",
      "Procesando imagen 11/129\n",
      "Procesando imagen 12/129\n",
      "Procesando imagen 13/129\n",
      "Procesando imagen 14/129\n",
      "Procesando imagen 15/129\n",
      "Procesando imagen 16/129\n",
      "Procesando imagen 17/129\n",
      "Procesando imagen 18/129\n",
      "Procesando imagen 19/129\n",
      "Procesando imagen 20/129\n",
      "Procesando imagen 21/129\n",
      "Procesando imagen 22/129\n",
      "Procesando imagen 23/129\n",
      "Procesando imagen 24/129\n",
      "Procesando imagen 25/129\n",
      "Procesando imagen 26/129\n",
      "Procesando imagen 27/129\n",
      "Procesando imagen 28/129\n",
      "Procesando imagen 29/129\n",
      "Procesando imagen 30/129\n",
      "Procesando imagen 31/129\n",
      "Procesando imagen 32/129\n",
      "Procesando imagen 33/129\n",
      "Procesando imagen 34/129\n",
      "Procesando imagen 35/129\n",
      "Procesando imagen 36/129\n",
      "Procesando imagen 37/129\n",
      "Procesando imagen 38/129\n",
      "Procesando imagen 39/129\n",
      "Procesando imagen 40/129\n",
      "Procesando imagen 41/129\n",
      "Procesando imagen 42/129\n",
      "Procesando imagen 43/129\n",
      "Procesando imagen 44/129\n",
      "Procesando imagen 45/129\n",
      "Procesando imagen 46/129\n",
      "Procesando imagen 47/129\n",
      "Procesando imagen 48/129\n",
      "Procesando imagen 49/129\n",
      "Procesando imagen 50/129\n",
      "Procesando imagen 51/129\n",
      "Procesando imagen 52/129\n",
      "Procesando imagen 53/129\n",
      "Procesando imagen 54/129\n",
      "Procesando imagen 55/129\n",
      "Procesando imagen 56/129\n",
      "Procesando imagen 57/129\n",
      "Procesando imagen 58/129\n",
      "Procesando imagen 59/129\n",
      "Procesando imagen 60/129\n",
      "Procesando imagen 61/129\n",
      "Procesando imagen 62/129\n",
      "Procesando imagen 63/129\n",
      "Procesando imagen 64/129\n",
      "Procesando imagen 65/129\n",
      "Procesando imagen 66/129\n",
      "Procesando imagen 67/129\n",
      "Procesando imagen 68/129\n",
      "Procesando imagen 69/129\n",
      "Procesando imagen 70/129\n",
      "Procesando imagen 71/129\n",
      "Procesando imagen 72/129\n",
      "Procesando imagen 73/129\n",
      "Procesando imagen 74/129\n",
      "Procesando imagen 75/129\n",
      "Procesando imagen 76/129\n",
      "Procesando imagen 77/129\n",
      "Procesando imagen 78/129\n",
      "Procesando imagen 79/129\n",
      "Procesando imagen 80/129\n",
      "Procesando imagen 81/129\n",
      "Procesando imagen 82/129\n",
      "Procesando imagen 83/129\n",
      "Procesando imagen 84/129\n",
      "Procesando imagen 85/129\n",
      "Procesando imagen 86/129\n",
      "Procesando imagen 87/129\n",
      "Procesando imagen 88/129\n",
      "Procesando imagen 89/129\n",
      "Procesando imagen 90/129\n",
      "Procesando imagen 91/129\n",
      "Procesando imagen 92/129\n",
      "Procesando imagen 93/129\n",
      "Procesando imagen 94/129\n",
      "Procesando imagen 95/129\n",
      "Procesando imagen 96/129\n",
      "Procesando imagen 97/129\n",
      "Procesando imagen 98/129\n",
      "Procesando imagen 99/129\n",
      "Procesando imagen 100/129\n",
      "Procesando imagen 101/129\n",
      "Procesando imagen 102/129\n",
      "Procesando imagen 103/129\n",
      "Procesando imagen 104/129\n",
      "Procesando imagen 105/129\n",
      "Procesando imagen 106/129\n",
      "Procesando imagen 107/129\n",
      "Procesando imagen 108/129\n",
      "Procesando imagen 109/129\n",
      "Procesando imagen 110/129\n",
      "Procesando imagen 111/129\n",
      "Procesando imagen 112/129\n",
      "Procesando imagen 113/129\n",
      "Procesando imagen 114/129\n",
      "Procesando imagen 115/129\n",
      "Procesando imagen 116/129\n",
      "Procesando imagen 117/129\n",
      "Procesando imagen 118/129\n",
      "Procesando imagen 119/129\n",
      "Procesando imagen 120/129\n",
      "Procesando imagen 121/129\n",
      "Procesando imagen 122/129\n",
      "Procesando imagen 123/129\n",
      "Procesando imagen 124/129\n",
      "Procesando imagen 125/129\n",
      "Procesando imagen 126/129\n",
      "Procesando imagen 127/129\n",
      "Procesando imagen 128/129\n",
      "Procesando imagen 129/129\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    print(\"Procesando imagen {}/{}\".format(i + 1,len(imagePaths)))\n",
    "    #print(imagePath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb) #Detectando las caras\n",
    "    \n",
    "    #Creando los vectores\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # Construyendo un diccionario con en el nombre de la imagen, el lugar donde esta la cara y el \n",
    "    # vector de caracteristicas\n",
    "    d = [{\"imagePath\": imagePath, \"loc\": box, \"encoding\": enc}\n",
    "        for (box, enc) in zip(boxes, encodings)]\n",
    "    data.extend(d)\n",
    "\n",
    "# Guardando los vectores en un formato en que no me importa la serializacion\n",
    "f = open('encodings', \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardando los vectores cuando si me importa la serializacion\n",
    "with open('encodings.txt', 'w') as f:\n",
    "    for item in data:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '{'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b1ac16d5145a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encodings.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mencodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '{'."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data = pickle.loads(open('encodings.txt', \"rb\").read())\n",
    "data = np.array(data)\n",
    "encodings = [d[\"encoding\"] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] clustering...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
       "       metric_params=None, min_samples=5, n_jobs=4, p=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster the embeddings\n",
    "print(\"[INFO] clustering...\")\n",
    "clt = DBSCAN(metric=\"euclidean\", n_jobs=4)\n",
    "clt.fit(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] # unique faces: 5\n"
     ]
    }
   ],
   "source": [
    "# determine the total number of unique faces found in the dataset\n",
    "labelIDs = np.unique(clt.labels_)\n",
    "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
    "print(\"[INFO] # unique faces: {}\".format(numUniqueFaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] faces for face ID: -1\n",
      "[INFO] faces for face ID: 0\n",
      "[INFO] faces for face ID: 1\n",
      "[INFO] faces for face ID: 2\n",
      "[INFO] faces for face ID: 3\n",
      "[INFO] faces for face ID: 4\n"
     ]
    }
   ],
   "source": [
    "for labelID in labelIDs:\n",
    "\t# find all indexes into the `data` array that belong to the\n",
    "\t# current label ID, then randomly sample a maximum of 25 indexes\n",
    "\t# from the set\n",
    "\tprint(\"[INFO] faces for face ID: {}\".format(labelID))\n",
    "\tidxs = np.where(clt.labels_ == labelID)[0]\n",
    "\tidxs = np.random.choice(idxs, size=min(25, len(idxs)),\n",
    "\t\treplace=False)\n",
    "\n",
    "\t# initialize the list of faces to include in the montage\n",
    "\tfaces = []\n",
    "\n",
    "\t# loop over the sampled indexes\n",
    "\tfor i in idxs:\n",
    "\t\t# load the input image and extract the face ROI\n",
    "\t\timage = cv2.imread(data[i][\"imagePath\"])\n",
    "\t\t(top, right, bottom, left) = data[i][\"loc\"]\n",
    "\t\tface = image[top:bottom, left:right]\n",
    "\n",
    "\t\t# force resize the face ROI to 96x96 and then add it to the\n",
    "\t\t# faces montage list\n",
    "\t\tface = cv2.resize(face, (96, 96))\n",
    "\t\tfaces.append(face)\n",
    "\n",
    "\t# create a montage using 96x96 \"tiles\" with 5 rows and 5 columns\n",
    "\tmontage = build_montages(faces, (96, 96), (5, 5))[0]\n",
    "\t\n",
    "\t# show the output montage\n",
    "\ttitle = \"Face ID #{}\".format(labelID)\n",
    "\ttitle = \"Unknown Faces\" if labelID == -1 else title\n",
    "\tcv2.imshow(title, montage)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(imagePaths[0])\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(44, 151, 152, 44), (31, 213, 74, 170)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = face_recognition.face_locations(rgb,model='cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando imagen 1/129\n",
      "dataset\\00000000.jpg\n",
      "Procesando imagen 2/129\n",
      "dataset\\00000001.jpg\n",
      "Procesando imagen 3/129\n",
      "dataset\\00000002.jpg\n",
      "Procesando imagen 4/129\n",
      "dataset\\00000003.jpg\n",
      "Procesando imagen 5/129\n",
      "dataset\\00000004.jpg\n",
      "Procesando imagen 6/129\n",
      "dataset\\00000005.jpg\n",
      "Procesando imagen 7/129\n",
      "dataset\\00000006.jpg\n",
      "Procesando imagen 8/129\n",
      "dataset\\00000007.jpg\n",
      "Procesando imagen 9/129\n",
      "dataset\\00000008.jpg\n",
      "Procesando imagen 10/129\n",
      "dataset\\00000009.jpg\n",
      "Procesando imagen 11/129\n",
      "dataset\\00000010.jpg\n",
      "Procesando imagen 12/129\n",
      "dataset\\00000011.jpg\n",
      "Procesando imagen 13/129\n",
      "dataset\\00000012.jpg\n",
      "Procesando imagen 14/129\n",
      "dataset\\00000013.jpg\n",
      "Procesando imagen 15/129\n",
      "dataset\\00000014.jpg\n",
      "Procesando imagen 16/129\n",
      "dataset\\00000015.jpg\n",
      "Procesando imagen 17/129\n",
      "dataset\\00000016.jpg\n",
      "Procesando imagen 18/129\n",
      "dataset\\00000017.jpg\n",
      "Procesando imagen 19/129\n",
      "dataset\\00000018.jpg\n",
      "Procesando imagen 20/129\n",
      "dataset\\00000019.jpg\n",
      "Procesando imagen 21/129\n",
      "dataset\\00000020.jpg\n",
      "Procesando imagen 22/129\n",
      "dataset\\00000021.jpg\n",
      "Procesando imagen 23/129\n",
      "dataset\\00000022.jpg\n",
      "Procesando imagen 24/129\n",
      "dataset\\00000023.jpg\n",
      "Procesando imagen 25/129\n",
      "dataset\\00000024.jpg\n",
      "Procesando imagen 26/129\n",
      "dataset\\00000025.jpg\n",
      "Procesando imagen 27/129\n",
      "dataset\\00000026.jpg\n",
      "Procesando imagen 28/129\n",
      "dataset\\00000027.jpg\n",
      "Procesando imagen 29/129\n",
      "dataset\\00000028.jpg\n",
      "Procesando imagen 30/129\n",
      "dataset\\00000029.jpg\n",
      "Procesando imagen 31/129\n",
      "dataset\\00000030.jpg\n",
      "Procesando imagen 32/129\n",
      "dataset\\00000031.jpg\n",
      "Procesando imagen 33/129\n",
      "dataset\\00000032.jpg\n",
      "Procesando imagen 34/129\n",
      "dataset\\00000033.jpg\n",
      "Procesando imagen 35/129\n",
      "dataset\\00000034.jpg\n",
      "Procesando imagen 36/129\n",
      "dataset\\00000035.jpg\n",
      "Procesando imagen 37/129\n",
      "dataset\\00000036.jpg\n",
      "Procesando imagen 38/129\n",
      "dataset\\00000037.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Detectar caras en las 129 imágenes\n",
    "data = []\n",
    "\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    print(\"Procesando imagen {}/{}\".format(i + 1,len(imagePaths)))\n",
    "    print(imagePath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb,model='cnn') #Detectando las caras\n",
    "    \n",
    "    #Creando los vectores\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # Construyendo un diccionario con en el nombre de la imagen, el lugar donde esta la cara y el \n",
    "    # vector de caracteristicas\n",
    "    d = [{\"imagePath\": imagePath, \"loc\": box, \"encoding\": enc}\n",
    "        for (box, enc) in zip(boxes, encodings)]\n",
    "    data.extend(d)\n",
    "\n",
    "# Guardando los vectores en un formato en que no me importa la serializacion\n",
    "f = open('encodings', \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
